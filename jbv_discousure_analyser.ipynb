{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFQo9QyrkCP8",
        "outputId": "0862f858-21ac-4abc-9c3d-2badf22e13a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/253.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install python-docx --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "import json\n",
        "from typing import List, Dict\n",
        "import os\n",
        "from collections import Counter\n",
        "import time"
      ],
      "metadata": {
        "id": "ufjcwJrFkKSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"DEEPSEEK_API_KEY\"] = \"sk-af880d796c074ee9853bf9957798a46d\""
      ],
      "metadata": {
        "id": "52ayIwwdkNgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kiaSM2ijkRXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DiscourseAnalyzer:\n",
        "    \"\"\"Analyzes academic abstracts to identify research discourses\"\"\"\n",
        "\n",
        "    def __init__(self, api_key: str = None):\n",
        "        \"\"\"\n",
        "        Initialize the analyzer with DeepSeek API\n",
        "\n",
        "        Args:\n",
        "            api_key: DeepSeek API key (if None, reads from DEEPSEEK_API_KEY env variable)\n",
        "        \"\"\"\n",
        "        self.api_key = api_key or os.environ.get('DEEPSEEK_API_KEY')\n",
        "        if not self.api_key:\n",
        "            raise ValueError(\"API key must be provided or set in DEEPSEEK_API_KEY environment variable\")\n",
        "\n",
        "        self.client = OpenAI(\n",
        "            api_key=self.api_key,\n",
        "            base_url=\"https://api.deepseek.com\"\n",
        "        )\n",
        "        self.model = \"deepseek-chat\"\n",
        "\n",
        "    def analyze_single_abstract(self, abstract: str, title: str = \"\") -> Dict:\n",
        "        \"\"\"\n",
        "        Analyze a single abstract to identify its discourse themes\n",
        "\n",
        "        Args:\n",
        "            abstract: The abstract text\n",
        "            title: Optional article title for context\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with discourse analysis results\n",
        "        \"\"\"\n",
        "        prompt = f\"\"\"Analyze the following academic article abstract from the Journal of Business Venturing.\n",
        "\n",
        "Title: {title}\n",
        "Abstract: {abstract}\n",
        "\n",
        "Please identify and categorize the key research discourse(s) in this abstract. Provide your analysis in JSON format with the following structure:\n",
        "\n",
        "{{\n",
        "    \"primary_discourse\": \"Main research discourse/theme\",\n",
        "    \"secondary_discourses\": [\"Additional discourse 1\", \"Additional discourse 2\"],\n",
        "    \"theoretical_perspectives\": [\"Theoretical lens 1\", \"Theoretical lens 2\"],\n",
        "    \"research_context\": \"Brief description of the research setting/context\",\n",
        "    \"key_concepts\": [\"Concept 1\", \"Concept 2\", \"Concept 3\"],\n",
        "    \"methodological_approach\": \"Research methodology type\"\n",
        "}}\n",
        "\n",
        "Be specific and use established academic terminology. Focus on identifying:\n",
        "- The main theoretical conversation this research contributes to\n",
        "- Key concepts and constructs being examined\n",
        "- The broader academic discourse(s) this work engages with\n",
        "\n",
        "Respond ONLY with the JSON object, no additional text.\"\"\"\n",
        "\n",
        "        try:\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=self.model,\n",
        "                messages=[\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                temperature=0.3,\n",
        "                max_tokens=2000\n",
        "            )\n",
        "\n",
        "            # Extract the response text\n",
        "            response_text = response.choices[0].message.content\n",
        "\n",
        "            # Try to parse JSON from the response\n",
        "            # Remove markdown code blocks if present\n",
        "            if \"```json\" in response_text:\n",
        "                response_text = response_text.split(\"```json\")[1].split(\"```\")[0].strip()\n",
        "            elif \"```\" in response_text:\n",
        "                response_text = response_text.split(\"```\")[1].split(\"```\")[0].strip()\n",
        "\n",
        "            result = json.loads(response_text)\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error analyzing abstract: {e}\")\n",
        "            return None\n",
        "\n",
        "    def analyze_batch(self, df: pd.DataFrame, abstract_column: str = 'abstract',\n",
        "                     title_column: str = 'title', sample_size: int = None,\n",
        "                     delay: float = 1.0) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Analyze a batch of abstracts\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame containing the articles\n",
        "            abstract_column: Name of the column containing abstracts\n",
        "            title_column: Name of the column containing titles\n",
        "            sample_size: Optional number of articles to analyze (None = all)\n",
        "            delay: Delay in seconds between API calls to avoid rate limits\n",
        "\n",
        "        Returns:\n",
        "            DataFrame with added analysis columns\n",
        "        \"\"\"\n",
        "        # Work with a copy\n",
        "        df_analysis = df.copy()\n",
        "\n",
        "        # Sample if requested\n",
        "        if sample_size and sample_size < len(df_analysis):\n",
        "            df_analysis = df_analysis.sample(n=sample_size, random_state=42)\n",
        "\n",
        "        # Initialize new columns\n",
        "        df_analysis['primary_discourse'] = None\n",
        "        df_analysis['secondary_discourses'] = None\n",
        "        df_analysis['theoretical_perspectives'] = None\n",
        "        df_analysis['research_context'] = None\n",
        "        df_analysis['key_concepts'] = None\n",
        "        df_analysis['methodological_approach'] = None\n",
        "\n",
        "        total = len(df_analysis)\n",
        "\n",
        "        for idx, row in df_analysis.iterrows():\n",
        "            print(f\"Analyzing article {idx + 1}/{total}...\")\n",
        "\n",
        "            abstract = row[abstract_column]\n",
        "            title = row[title_column] if title_column in df_analysis.columns else \"\"\n",
        "\n",
        "            # Skip if abstract is missing\n",
        "            if pd.isna(abstract) or not abstract:\n",
        "                print(f\"  Skipping - no abstract\")\n",
        "                continue\n",
        "\n",
        "            result = self.analyze_single_abstract(abstract, title)\n",
        "\n",
        "            if result:\n",
        "                df_analysis.at[idx, 'primary_discourse'] = result.get('primary_discourse', '')\n",
        "                df_analysis.at[idx, 'secondary_discourses'] = json.dumps(result.get('secondary_discourses', []))\n",
        "                df_analysis.at[idx, 'theoretical_perspectives'] = json.dumps(result.get('theoretical_perspectives', []))\n",
        "                df_analysis.at[idx, 'research_context'] = result.get('research_context', '')\n",
        "                df_analysis.at[idx, 'key_concepts'] = json.dumps(result.get('key_concepts', []))\n",
        "                df_analysis.at[idx, 'methodological_approach'] = result.get('methodological_approach', '')\n",
        "\n",
        "            # Rate limiting\n",
        "            time.sleep(delay)\n",
        "\n",
        "        return df_analysis\n",
        "\n",
        "    def generate_comprehensive_overview(self, df_analyzed: pd.DataFrame) -> str:\n",
        "        \"\"\"\n",
        "        Generate a comprehensive overview of all discourses identified\n",
        "\n",
        "        Args:\n",
        "            df_analyzed: DataFrame with analysis results\n",
        "\n",
        "        Returns:\n",
        "            Comprehensive overview text\n",
        "        \"\"\"\n",
        "        # Collect all discourses\n",
        "        all_primary = df_analyzed['primary_discourse'].dropna().tolist()\n",
        "\n",
        "        all_secondary = []\n",
        "        for item in df_analyzed['secondary_discourses'].dropna():\n",
        "            try:\n",
        "                all_secondary.extend(json.loads(item))\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        all_theoretical = []\n",
        "        for item in df_analyzed['theoretical_perspectives'].dropna():\n",
        "            try:\n",
        "                all_theoretical.extend(json.loads(item))\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        all_concepts = []\n",
        "        for item in df_analyzed['key_concepts'].dropna():\n",
        "            try:\n",
        "                all_concepts.extend(json.loads(item))\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        all_methods = df_analyzed['methodological_approach'].dropna().tolist()\n",
        "\n",
        "        # Create summary prompt\n",
        "        summary_data = {\n",
        "            \"primary_discourses\": all_primary,\n",
        "            \"secondary_discourses\": all_secondary,\n",
        "            \"theoretical_perspectives\": all_theoretical,\n",
        "            \"key_concepts\": all_concepts,\n",
        "            \"methodological_approaches\": all_methods,\n",
        "            \"total_articles\": len(df_analyzed)\n",
        "        }\n",
        "\n",
        "        prompt = f\"\"\"Based on the analysis of {len(df_analyzed)} articles from the Journal of Business Venturing (2023-present),\n",
        "I have identified the following research elements:\n",
        "\n",
        "Primary Discourses (main themes):\n",
        "{Counter(all_primary).most_common(20)}\n",
        "\n",
        "Secondary Discourses:\n",
        "{Counter(all_secondary).most_common(20)}\n",
        "\n",
        "Theoretical Perspectives:\n",
        "{Counter(all_theoretical).most_common(20)}\n",
        "\n",
        "Key Concepts:\n",
        "{Counter(all_concepts).most_common(30)}\n",
        "\n",
        "Methodological Approaches:\n",
        "{Counter(all_methods).most_common(15)}\n",
        "\n",
        "Please provide a comprehensive overview (1000-1500 words) of the research discourses being discussed in the Journal of Business Venturing.\n",
        "Your overview should:\n",
        "\n",
        "1. Identify the major thematic clusters and research streams\n",
        "2. Discuss how these discourses relate to each other\n",
        "3. Highlight any emerging trends or shifts in focus\n",
        "4. Note the dominant theoretical perspectives being employed\n",
        "5. Discuss the methodological diversity (or lack thereof)\n",
        "6. Provide insights into the current state and future directions of business venturing research\n",
        "\n",
        "Write this as an academic overview suitable for a literature review or research proposal.\"\"\"\n",
        "\n",
        "        try:\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=self.model,\n",
        "                messages=[\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                temperature=0.5,\n",
        "                max_tokens=4000\n",
        "            )\n",
        "\n",
        "            return response.choices[0].message.content\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating overview: {e}\")\n",
        "            return None"
      ],
      "metadata": {
        "id": "WVOw519vjZZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "19HgJAZokSbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"Main execution function\"\"\"\n",
        "\n",
        "    # Configuration\n",
        "    CSV_FILE = \"jbv_papers.csv\"  # Replace with your CSV filename\n",
        "    ABSTRACT_COLUMN = \"Abstract\"  # Replace with your abstract column name\n",
        "    TITLE_COLUMN = \"title\"  # Replace with your title column name\n",
        "    SAMPLE_SIZE = None  # Set to a number to analyze only a sample, or None for all\n",
        "    OUTPUT_FILE = \"discourse_analysis_results.csv\"\n",
        "    OVERVIEW_FILE = \"discourse_overview.txt\"\n",
        "\n",
        "    print(\"=== Journal Article Discourse Analysis ===\\n\")\n",
        "\n",
        "    # Initialize analyzer\n",
        "    print(\"Initializing analyzer...\")\n",
        "    analyzer = DiscourseAnalyzer()\n",
        "\n",
        "    # Load data\n",
        "    print(f\"Loading data from {CSV_FILE}...\")\n",
        "    df = pd.read_csv(CSV_FILE)\n",
        "    print(f\"Loaded {len(df)} articles\\n\")\n",
        "\n",
        "    # Display column names to help user verify\n",
        "    print(\"Available columns:\", df.columns.tolist())\n",
        "    print()\n",
        "\n",
        "    # Analyze articles\n",
        "    print(\"Starting analysis...\")\n",
        "    df_results = analyzer.analyze_batch(\n",
        "        df,\n",
        "        abstract_column=ABSTRACT_COLUMN,\n",
        "        title_column=TITLE_COLUMN,\n",
        "        sample_size=SAMPLE_SIZE,\n",
        "        delay=1.0  # Adjust delay as needed for rate limits\n",
        "    )\n",
        "\n",
        "    # Save detailed results\n",
        "    print(f\"\\nSaving detailed results to {OUTPUT_FILE}...\")\n",
        "    df_results.to_csv(OUTPUT_FILE, index=False)\n",
        "\n",
        "    # Generate comprehensive overview\n",
        "    print(\"Generating comprehensive overview...\")\n",
        "    overview = analyzer.generate_comprehensive_overview(df_results)\n",
        "\n",
        "    if overview:\n",
        "        print(f\"Saving overview to {OVERVIEW_FILE}...\")\n",
        "        with open(OVERVIEW_FILE, 'w', encoding='utf-8') as f:\n",
        "            f.write(overview)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"COMPREHENSIVE OVERVIEW\")\n",
        "        print(\"=\"*70 + \"\\n\")\n",
        "        print(overview)\n",
        "\n",
        "    print(\"\\n=== Analysis Complete ===\")\n",
        "    print(f\"Detailed results saved to: {OUTPUT_FILE}\")\n",
        "    print(f\"Overview saved to: {OVERVIEW_FILE}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "ESq1sLx2jo8u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2deca17-808b-4e91-8b9e-2c2c6d8b9393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Journal Article Discourse Analysis ===\n",
            "\n",
            "Initializing analyzer...\n",
            "Loading data from jbv_papers.csv...\n",
            "Loaded 382 articles\n",
            "\n",
            "Available columns: ['Authors', 'Author full names', 'Author(s) ID', 'Title', 'Year', 'Source title', 'Volume', 'Issue', 'Art. No.', 'Page start', 'Page end', 'Cited by', 'DOI', 'Link', 'Affiliations', 'Authors with affiliations', 'Abstract', 'Author Keywords', 'Document Type', 'Source']\n",
            "\n",
            "Starting analysis...\n",
            "Analyzing article 1/382...\n",
            "Analyzing article 2/382...\n",
            "Analyzing article 3/382...\n",
            "Analyzing article 4/382...\n",
            "Analyzing article 5/382...\n",
            "Analyzing article 6/382...\n",
            "Analyzing article 7/382...\n",
            "Analyzing article 8/382...\n",
            "Analyzing article 9/382...\n",
            "Analyzing article 10/382...\n",
            "Analyzing article 11/382...\n",
            "Analyzing article 12/382...\n",
            "Analyzing article 13/382...\n",
            "Analyzing article 14/382...\n",
            "Analyzing article 15/382...\n",
            "Analyzing article 16/382...\n",
            "Analyzing article 17/382...\n",
            "Analyzing article 18/382...\n",
            "Analyzing article 19/382...\n",
            "Analyzing article 20/382...\n",
            "Analyzing article 21/382...\n",
            "Analyzing article 22/382...\n",
            "Analyzing article 23/382...\n",
            "Analyzing article 24/382...\n",
            "Analyzing article 25/382...\n",
            "Analyzing article 26/382...\n",
            "Analyzing article 27/382...\n",
            "Analyzing article 28/382...\n",
            "Analyzing article 29/382...\n",
            "Analyzing article 30/382...\n",
            "Analyzing article 31/382...\n",
            "Analyzing article 32/382...\n",
            "Analyzing article 33/382...\n",
            "Analyzing article 34/382...\n",
            "Analyzing article 35/382...\n",
            "Analyzing article 36/382...\n",
            "Analyzing article 37/382...\n",
            "Analyzing article 38/382...\n",
            "Analyzing article 39/382...\n",
            "Analyzing article 40/382...\n",
            "Analyzing article 41/382...\n",
            "Analyzing article 42/382...\n",
            "Analyzing article 43/382...\n",
            "Analyzing article 44/382...\n",
            "Analyzing article 45/382...\n",
            "Analyzing article 46/382...\n",
            "Analyzing article 47/382...\n",
            "Analyzing article 48/382...\n",
            "Analyzing article 49/382...\n",
            "Analyzing article 50/382...\n",
            "Analyzing article 51/382...\n",
            "Analyzing article 52/382...\n",
            "Analyzing article 53/382...\n",
            "Analyzing article 54/382...\n",
            "Analyzing article 55/382...\n",
            "Analyzing article 56/382...\n",
            "Analyzing article 57/382...\n",
            "Analyzing article 58/382...\n",
            "Analyzing article 59/382...\n",
            "Analyzing article 60/382...\n",
            "Analyzing article 61/382...\n",
            "Analyzing article 62/382...\n",
            "Analyzing article 63/382...\n",
            "Analyzing article 64/382...\n",
            "Analyzing article 65/382...\n",
            "Analyzing article 66/382...\n",
            "Analyzing article 67/382...\n",
            "Analyzing article 68/382...\n",
            "Analyzing article 69/382...\n",
            "Analyzing article 70/382...\n",
            "Analyzing article 71/382...\n",
            "Analyzing article 72/382...\n",
            "Analyzing article 73/382...\n",
            "Analyzing article 74/382...\n",
            "Analyzing article 75/382...\n",
            "Analyzing article 76/382...\n",
            "Analyzing article 77/382...\n",
            "Analyzing article 78/382...\n",
            "Analyzing article 79/382...\n",
            "Analyzing article 80/382...\n",
            "Analyzing article 81/382...\n",
            "Analyzing article 82/382...\n",
            "Analyzing article 83/382...\n",
            "Analyzing article 84/382...\n",
            "Analyzing article 85/382...\n",
            "Analyzing article 86/382...\n",
            "Analyzing article 87/382...\n",
            "Analyzing article 88/382...\n",
            "Analyzing article 89/382...\n",
            "Analyzing article 90/382...\n",
            "Analyzing article 91/382...\n",
            "Analyzing article 92/382...\n",
            "Analyzing article 93/382...\n",
            "Analyzing article 94/382...\n",
            "Analyzing article 95/382...\n",
            "Analyzing article 96/382...\n",
            "Analyzing article 97/382...\n",
            "Analyzing article 98/382...\n",
            "Analyzing article 99/382...\n",
            "Analyzing article 100/382...\n",
            "Analyzing article 101/382...\n",
            "Analyzing article 102/382...\n",
            "Analyzing article 103/382...\n",
            "Analyzing article 104/382...\n",
            "Analyzing article 105/382...\n",
            "Analyzing article 106/382...\n",
            "Analyzing article 107/382...\n",
            "Analyzing article 108/382...\n",
            "Analyzing article 109/382...\n",
            "Analyzing article 110/382...\n",
            "Analyzing article 111/382...\n",
            "Analyzing article 112/382...\n",
            "Analyzing article 113/382...\n",
            "Analyzing article 114/382...\n",
            "Analyzing article 115/382...\n",
            "Analyzing article 116/382...\n",
            "Analyzing article 117/382...\n",
            "Analyzing article 118/382...\n",
            "Analyzing article 119/382...\n",
            "Analyzing article 120/382...\n",
            "Analyzing article 121/382...\n",
            "Analyzing article 122/382...\n",
            "Analyzing article 123/382...\n",
            "Analyzing article 124/382...\n",
            "Analyzing article 125/382...\n",
            "Analyzing article 126/382...\n",
            "Analyzing article 127/382...\n",
            "Analyzing article 128/382...\n",
            "Analyzing article 129/382...\n",
            "Analyzing article 130/382...\n",
            "Analyzing article 131/382...\n",
            "Analyzing article 132/382...\n",
            "Analyzing article 133/382...\n",
            "Analyzing article 134/382...\n",
            "Analyzing article 135/382...\n",
            "Analyzing article 136/382...\n",
            "Analyzing article 137/382...\n",
            "Analyzing article 138/382...\n",
            "Analyzing article 139/382...\n",
            "Analyzing article 140/382...\n",
            "Analyzing article 141/382...\n",
            "Analyzing article 142/382...\n",
            "Analyzing article 143/382...\n",
            "Analyzing article 144/382...\n",
            "Analyzing article 145/382...\n",
            "Analyzing article 146/382...\n",
            "Analyzing article 147/382...\n",
            "Analyzing article 148/382...\n",
            "Analyzing article 149/382...\n",
            "Analyzing article 150/382...\n",
            "Analyzing article 151/382...\n",
            "Analyzing article 152/382...\n",
            "Analyzing article 153/382...\n",
            "Analyzing article 154/382...\n",
            "Analyzing article 155/382...\n",
            "Analyzing article 156/382...\n",
            "Analyzing article 157/382...\n",
            "Analyzing article 158/382...\n",
            "Analyzing article 159/382...\n",
            "Analyzing article 160/382...\n",
            "Analyzing article 161/382...\n",
            "Analyzing article 162/382...\n",
            "Analyzing article 163/382...\n",
            "Analyzing article 164/382...\n",
            "Analyzing article 165/382...\n",
            "Analyzing article 166/382...\n",
            "Analyzing article 167/382...\n",
            "Analyzing article 168/382...\n",
            "Analyzing article 169/382...\n",
            "Analyzing article 170/382...\n",
            "Analyzing article 171/382...\n",
            "Analyzing article 172/382...\n",
            "Analyzing article 173/382...\n",
            "Analyzing article 174/382...\n",
            "Analyzing article 175/382...\n",
            "Analyzing article 176/382...\n",
            "Analyzing article 177/382...\n",
            "Analyzing article 178/382...\n",
            "Analyzing article 179/382...\n",
            "Analyzing article 180/382...\n",
            "Analyzing article 181/382...\n",
            "Analyzing article 182/382...\n",
            "Analyzing article 183/382...\n",
            "Analyzing article 184/382...\n",
            "Analyzing article 185/382...\n",
            "Analyzing article 186/382...\n",
            "Analyzing article 187/382...\n",
            "Analyzing article 188/382...\n",
            "Analyzing article 189/382...\n",
            "Analyzing article 190/382...\n",
            "Analyzing article 191/382...\n",
            "Analyzing article 192/382...\n",
            "Analyzing article 193/382...\n",
            "Analyzing article 194/382...\n",
            "Analyzing article 195/382...\n",
            "Analyzing article 196/382...\n",
            "Analyzing article 197/382...\n",
            "Analyzing article 198/382...\n",
            "Analyzing article 199/382...\n",
            "Analyzing article 200/382...\n",
            "Analyzing article 201/382...\n",
            "Analyzing article 202/382...\n",
            "Analyzing article 203/382...\n",
            "Analyzing article 204/382...\n",
            "Analyzing article 205/382...\n",
            "Analyzing article 206/382...\n",
            "Analyzing article 207/382...\n",
            "Analyzing article 208/382...\n",
            "Analyzing article 209/382...\n",
            "Analyzing article 210/382...\n",
            "Analyzing article 211/382...\n",
            "Analyzing article 212/382...\n",
            "Analyzing article 213/382...\n",
            "Analyzing article 214/382...\n",
            "Analyzing article 215/382...\n",
            "Analyzing article 216/382...\n",
            "Analyzing article 217/382...\n",
            "Analyzing article 218/382...\n",
            "Analyzing article 219/382...\n",
            "Analyzing article 220/382...\n",
            "Analyzing article 221/382...\n",
            "Analyzing article 222/382...\n",
            "Analyzing article 223/382...\n",
            "Analyzing article 224/382...\n",
            "Analyzing article 225/382...\n",
            "Analyzing article 226/382...\n",
            "Analyzing article 227/382...\n",
            "Analyzing article 228/382...\n",
            "Analyzing article 229/382...\n",
            "Analyzing article 230/382...\n",
            "Analyzing article 231/382...\n",
            "Analyzing article 232/382...\n",
            "Analyzing article 233/382...\n",
            "Analyzing article 234/382...\n",
            "Analyzing article 235/382...\n",
            "Analyzing article 236/382...\n",
            "Analyzing article 237/382...\n",
            "Analyzing article 238/382...\n",
            "Analyzing article 239/382...\n",
            "Analyzing article 240/382...\n",
            "Analyzing article 241/382...\n",
            "Analyzing article 242/382...\n",
            "Analyzing article 243/382...\n",
            "Analyzing article 244/382...\n",
            "Analyzing article 245/382...\n",
            "Analyzing article 246/382...\n",
            "Analyzing article 247/382...\n",
            "Analyzing article 248/382...\n",
            "Analyzing article 249/382...\n",
            "Analyzing article 250/382...\n",
            "Analyzing article 251/382...\n",
            "Analyzing article 252/382...\n",
            "Analyzing article 253/382...\n",
            "Analyzing article 254/382...\n",
            "Analyzing article 255/382...\n",
            "Analyzing article 256/382...\n",
            "Analyzing article 257/382...\n",
            "Analyzing article 258/382...\n",
            "Analyzing article 259/382...\n",
            "Analyzing article 260/382...\n",
            "Analyzing article 261/382...\n",
            "Analyzing article 262/382...\n",
            "Analyzing article 263/382...\n",
            "Analyzing article 264/382...\n",
            "Analyzing article 265/382...\n",
            "Analyzing article 266/382...\n",
            "Analyzing article 267/382...\n",
            "Analyzing article 268/382...\n",
            "Analyzing article 269/382...\n",
            "Analyzing article 270/382...\n",
            "Analyzing article 271/382...\n",
            "Analyzing article 272/382...\n",
            "Analyzing article 273/382...\n",
            "Analyzing article 274/382...\n",
            "Analyzing article 275/382...\n",
            "Analyzing article 276/382...\n",
            "Analyzing article 277/382...\n",
            "Analyzing article 278/382...\n",
            "Analyzing article 279/382...\n",
            "Analyzing article 280/382...\n",
            "Analyzing article 281/382...\n",
            "Analyzing article 282/382...\n",
            "Analyzing article 283/382...\n",
            "Analyzing article 284/382...\n",
            "Analyzing article 285/382...\n",
            "Analyzing article 286/382...\n",
            "Analyzing article 287/382...\n",
            "Analyzing article 288/382...\n",
            "Analyzing article 289/382...\n",
            "Analyzing article 290/382...\n",
            "Analyzing article 291/382...\n",
            "Analyzing article 292/382...\n",
            "Analyzing article 293/382...\n",
            "Analyzing article 294/382...\n",
            "Analyzing article 295/382...\n",
            "Analyzing article 296/382...\n",
            "Analyzing article 297/382...\n",
            "Analyzing article 298/382...\n",
            "Analyzing article 299/382...\n",
            "Analyzing article 300/382...\n",
            "Analyzing article 301/382...\n",
            "Analyzing article 302/382...\n",
            "Analyzing article 303/382...\n",
            "Analyzing article 304/382...\n",
            "Analyzing article 305/382...\n",
            "Analyzing article 306/382...\n",
            "Analyzing article 307/382...\n",
            "Analyzing article 308/382...\n",
            "Analyzing article 309/382...\n",
            "Analyzing article 310/382...\n",
            "Analyzing article 311/382...\n",
            "Analyzing article 312/382...\n",
            "Analyzing article 313/382...\n",
            "Analyzing article 314/382...\n",
            "Analyzing article 315/382...\n",
            "Analyzing article 316/382...\n",
            "Analyzing article 317/382...\n",
            "Analyzing article 318/382...\n",
            "Analyzing article 319/382...\n",
            "Analyzing article 320/382...\n",
            "Analyzing article 321/382...\n",
            "Analyzing article 322/382...\n",
            "Analyzing article 323/382...\n",
            "Analyzing article 324/382...\n",
            "Analyzing article 325/382...\n",
            "Analyzing article 326/382...\n",
            "Analyzing article 327/382...\n",
            "Analyzing article 328/382...\n",
            "Analyzing article 329/382...\n",
            "Analyzing article 330/382...\n",
            "Analyzing article 331/382...\n",
            "Analyzing article 332/382...\n",
            "Analyzing article 333/382...\n",
            "Analyzing article 334/382...\n",
            "Analyzing article 335/382...\n",
            "Analyzing article 336/382...\n",
            "Analyzing article 337/382...\n",
            "Analyzing article 338/382...\n",
            "Analyzing article 339/382...\n",
            "Analyzing article 340/382...\n",
            "Analyzing article 341/382...\n",
            "Analyzing article 342/382...\n",
            "Analyzing article 343/382...\n",
            "Analyzing article 344/382...\n",
            "Analyzing article 345/382...\n",
            "Analyzing article 346/382...\n",
            "Analyzing article 347/382...\n",
            "Analyzing article 348/382...\n",
            "Analyzing article 349/382...\n",
            "Analyzing article 350/382...\n",
            "Analyzing article 351/382...\n",
            "Analyzing article 352/382...\n",
            "Analyzing article 353/382...\n",
            "Analyzing article 354/382...\n",
            "Analyzing article 355/382...\n",
            "Analyzing article 356/382...\n",
            "Analyzing article 357/382...\n",
            "Analyzing article 358/382...\n",
            "Analyzing article 359/382...\n",
            "Analyzing article 360/382...\n",
            "Analyzing article 361/382...\n",
            "Analyzing article 362/382...\n",
            "Analyzing article 363/382...\n",
            "Analyzing article 364/382...\n",
            "Analyzing article 365/382...\n",
            "Analyzing article 366/382...\n",
            "Analyzing article 367/382...\n",
            "Analyzing article 368/382...\n",
            "Analyzing article 369/382...\n",
            "Analyzing article 370/382...\n",
            "Analyzing article 371/382...\n",
            "Analyzing article 372/382...\n",
            "Analyzing article 373/382...\n",
            "Analyzing article 374/382...\n",
            "Analyzing article 375/382...\n",
            "Analyzing article 376/382...\n",
            "Analyzing article 377/382...\n",
            "Analyzing article 378/382...\n",
            "Analyzing article 379/382...\n",
            "Analyzing article 380/382...\n",
            "Analyzing article 381/382...\n",
            "Analyzing article 382/382...\n",
            "\n",
            "Saving detailed results to discourse_analysis_results.csv...\n",
            "Generating comprehensive overview...\n",
            "Saving overview to discourse_overview.txt...\n",
            "\n",
            "======================================================================\n",
            "COMPREHENSIVE OVERVIEW\n",
            "======================================================================\n",
            "\n",
            "### **An Overview of Contemporary Research Discourses in the Journal of Business Venturing (2023-Present)**\n",
            "\n",
            "The *Journal of Business Venturing (JBV)* remains a premier outlet for cutting-edge scholarship in entrepreneurship. An analysis of recent publications (2023-present) reveals a vibrant and multifaceted intellectual landscape. While the field continues to grapple with its foundational questions—how opportunities emerge, are acted upon, and lead to new value creation—the discourses have evolved in sophistication, scope, and reflexivity. This overview synthesizes the primary research streams, their interrelationships, theoretical and methodological tendencies, and points toward the field’s emerging trajectory.\n",
            "\n",
            "#### **1. Major Thematic Clusters and Research Streams**\n",
            "\n",
            "The research can be organized into several interconnected thematic clusters.\n",
            "\n",
            "**A. The Core of Entrepreneurship: Opportunity, Action, and Agency.** The most prominent discourse cluster reaffirms the centrality of the entrepreneurial opportunity construct, but with nuanced evolution. The traditional dichotomy of discovery versus creation is increasingly framed as a dynamic process of **“identification, evaluation, exploitation, and creation.”** This stream interrogates the micro-foundations of entrepreneurial action under conditions of **uncertainty**, heavily leveraging **Effectuation Theory** (the most cited perspective) and its key concepts like *effectual logic*, *affordable loss*, and *means-driven action*. This is no longer purely theoretical; it is applied to pressing dilemmas such as decision-making in pivots, navigating “pivot-hells,” and overcoming analysis-paralysis. Concurrently, research on **Entrepreneurial Cognition** (a major secondary discourse) explores the cognitive heuristics, biases, and prior knowledge that shape how entrepreneurs perceive and act upon ambiguous signals.\n",
            "\n",
            "**B. The Social and Institutional Embeddedness of Venturing.** A second major cluster examines the venture not as an atomistic entity but as embedded within complex social and institutional fabrics. This includes:\n",
            "*   **Ecosystems and Support Structures:** Research critically examines **Entrepreneurial Ecosystems (EEs)**, moving beyond descriptive mapping to analyze their *inclusive evolution*, the role of peripheral actors, and the reconceptualization of accelerators and incubators as **“co-constructed social practice systems.”** **Institutional Theory** and **Stakeholder Theory** are key lenses here.\n",
            "*   **Identity, Legitimacy, and Rhetoric:** Studies on **Entrepreneurial Identity Formation** and **Social Identity Theory** explore how founders construct their roles. Closely linked is work on **Entrepreneurial Rhetoric and Persuasion**, often using **Signaling Theory**, to understand how ventures gain legitimacy and secure resources from stakeholders.\n",
            "*   **Societal Challenges and Emancipation:** Emerging strongly are themes of **Emancipatory Entrepreneurship**, **Social Entrepreneurship**, and **Entrepreneurship and Civic Engagement**. This stream investigates venturing as a mechanism for societal **systems change**, inclusion, and addressing grand challenges, often questioning traditional performance metrics.\n",
            "\n",
            "**C. The Human Dimension: Founders, Teams, and Well-being.** A significant cluster focuses on the individuals and teams at the heart of venturing.\n",
            "*   **Team Dynamics:** Drawing on **Upper Echelons Theory**, studies analyze **founder team composition**—particularly personality configurations—and its impact on venture outcomes and decision-making processes.\n",
            "*   **Entrepreneurial Well-being:** A notable and debated theme questions the personal cost of venturing, investigating whether self-employment is a **source of stress or improved mental well-being**. This links to concepts of **personal values** and **redemptive choice**, marking a shift toward considering the entrepreneur’s holistic life experience.\n",
            "\n",
            "**D. Critical Reflection and Field Maturation.** A self-referential discourse indicates a maturing field. Papers address **conceptual fragmentation and integration**, propose future agendas for sub-fields like **International Entrepreneurship (IE)**, and advocate for **Engaged Scholarship** and **Methodological innovation**. This meta-discourse seeks to enhance the relevance, rigor, and coherence of entrepreneurship research.\n",
            "\n",
            "#### **2. Interrelationships Among Discourses**\n",
            "\n",
            "These clusters are not siloed but deeply interwoven. The **core process of opportunity action (Cluster A)** is fundamentally shaped by **cognitive frameworks** (A), executed by **teams** (C) within **ecosystems** (B), and justified through **rhetoric** (B) to mobilize resources. For instance, a study on pivots (A) might examine team decision-making (C) under institutional pressures (B). Similarly, **emancipatory entrepreneurship (B)** often employs **effectual logic (A)** as a means-driven approach for marginalized actors and directly concerns founder **well-being (C)**. The **critical reflection (D)** seeks to make sense of and improve the connections between all these strands.\n",
            "\n",
            "#### **3. Emerging Trends and Shifts in Focus**\n",
            "\n",
            "Several shifts are apparent:\n",
            "*   **From Structure to Process and Practice:** There is a move away from static, structural views of ecosystems and support organizations toward understanding their dynamic, socially constructed processes and practices.\n",
            "*   **From Economic to Holistic Outcomes:** The expansion of dependent variables beyond financial performance to include well-being, societal impact, and systemic change represents a significant broadening of the field’s purpose.\n",
            "*   **From the Mainstream to the Marginal:** Increased attention to inclusivity, peripheries within ecosystems, and emancipatory goals signals a concern with entrepreneurship beyond the typical high-growth, technology-centric narrative.\n",
            "*   **From Certainty to Embracing Uncertainty:** **Uncertainty** is no longer just a contextual condition but a central construct around which theories of decision-making (effectuation), learning, and rhetoric are built.\n",
            "\n",
            "#### **4. Dominant Theoretical Perspectives**\n",
            "\n",
            "**Effectuation Theory** is the dominant theoretical lens, applied across clusters. **Institutional Theory** and **Signaling Theory** are paramount for understanding embeddedness and legitimacy. **Cognitive theories** provide the micro-foundations for action. Mid-range theories like **Resource-Based View**, **Human Capital Theory**, **Stakeholder Theory**, and **Social Identity Theory** are consistently employed as complementary frameworks. This reflects a field that successfully integrates psychological, sociological, and economic perspectives.\n",
            "\n",
            "#### **5. Methodological Diversity**\n",
            "\n",
            "The methodological landscape shows a strong qualitative, process-oriented inclination. The **qualitative case study**—especially longitudinal and multiple-case designs—is the workhorse for exploring “how” and “why” questions related to processes, practices, and meaning. There is a notable presence of **Conceptual/Theoretical papers** aimed at integration and agenda-setting. Quantitative work often employs **longitudinal panel data** for testing relationships. Promising, though less common, are innovative methods like **Participatory Action Research (PAR)**, which aligns with the engaged scholarship and emancipatory trends. While not absent, purely large-scale quantitative studies are less prominent in this snapshot, suggesting a field currently focused on deep exploration of mechanisms and context.\n",
            "\n",
            "#### **6. Current State and Future Directions**\n",
            "\n",
            "The current state of business venturing research in *JBV* is one of **consolidated complexity**. The field has solidified its core constructs (opportunity, uncertainty, effectuation) while dramatically expanding its scope of inquiry to be more inclusive, reflexive, and societally engaged.\n",
            "\n",
            "Future directions likely include:\n",
            "1.  **Deepening the Process Turn:** More fine-grained studies of micro-processes—of team conflict, rhetorical moves, daily bricolage, and emotional regulation—using rich temporal data.\n",
            "2.  **Theorizing Impact:** Developing robust theoretical frameworks and metrics for the non-financial outcomes of well-being, emancipation, and systemic change.\n",
            "3.  **Integrating Levels of Analysis:** Better bridging the cognitive (individual), interactional (team/network), and institutional (ecosystem/society) levels in single research designs.\n",
            "4.  **Engaging with New Paradigms:** Further exploration of the **circular economy** and other alternative paradigms as contexts for entrepreneurial action.\n",
            "5.  **Methodological Pluralism and Rigor:** A continued call for, and execution of, methodologically innovative, rigorous, and relevant studies, potentially blending advanced qualitative techniques with computational methods or field experiments.\n",
            "\n",
            "In conclusion, the discourses in *JBV* present a field that is dynamically wrestling with its own identity. It is simultaneously honing its central theories, expanding its moral and practical horizons, and critically examining its scholarly practices. This points to a vibrant future where entrepreneurship research seeks not only to explain venture creation but to understand and inform its role in shaping a more equitable, resilient, and flourishing society.\n",
            "\n",
            "=== Analysis Complete ===\n",
            "Detailed results saved to: discourse_analysis_results.csv\n",
            "Overview saved to: discourse_overview.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zJWUiiKxkXOX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}